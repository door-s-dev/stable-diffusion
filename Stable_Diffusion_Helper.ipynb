{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fladdict/stable-diffusion/blob/main/Stable_Diffusion_Helper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Oeq07oJ28B"
      },
      "source": [
        "# Stable Diffusion Helper\n",
        "\n",
        "画像生成AI [StableDiffusion](https://github.com/CompVis/stable-diffusion)をGUIで使えるノートブックです。\n",
        "重さや初期画像などの高度機能も実装。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBx4NIUO-B-2"
      },
      "source": [
        "## 使い方\n",
        "\n",
        "* このページ上部のメニューで、「ランタイム > ランタイムのタイプを変更」からGPUを有効化\n",
        "* [HuggingFace](https://huggingface.co/)でアカウントを作成\n",
        "* [StableDiffusionのモデルページ](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original)で、「利用規約」に合意する。\n",
        "* モデルファイル [sd-v1-4.ckpt](https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt) をダウンロード\n",
        "* モデルファイルを Google Drive等にアップロード\n",
        "* 下のセル 「1-1. Google Driveとの接続」を実行\n",
        "* 下のセル　「1-2. のフォーム」に、Google Driveにアップしたモデルのパスをセット\n",
        "* このページ上部のメニューで、「ランタイム > 全てのセルを実行」を選択\n",
        "* 一番したのほうにGUIが出現する。（近くのURLで別窓でも開ける）。\n",
        "\n",
        "## 不安程な場合\n",
        "* CUDA Errorが出る場合、メモリが足りてないのでGoogle Colab Pro（or Pro+)を検討ください。\n",
        "* 一度に大量の画像生成をしてGUIが不安程な場合、GUIを実行してるセルを一時停止して、そのセルを再実行してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq1JsCJiuQ58"
      },
      "source": [
        "## 重要\n",
        "\n",
        "「[Stable Diffusionの利用ライセンス](https://huggingface.co/spaces/CompVis/stable-diffusion-license)」を遵守してご利用ください。\n",
        "\n",
        "----\n",
        "\n",
        "## 利用前の注意\n",
        "画像生成AIは、インターネットそのものの縮図です。あらゆるものを生成するので、生成者は自分の生成物に責任をもつ必要があります。\n",
        "\n",
        "多くの場合、問題ある画像は偶発的というよりは、「生成者が意図的に指示」をすることで生成されます。以下のようなことを心がけましょう。\n",
        "\n",
        "\n",
        "* ポルノを含む、性的な画像を生成しない（海外基準で罰せられる可能性があります）。\n",
        "* 攻撃的な画像、差別的な画像、人を不快にする目的の画像を生成しない。\n",
        "* 政治的な主張に用いない。\n",
        "* 各種の文化バイアスがかかる場合があります。生成者が適宜バランスを調整をする（例、「結婚式」の画像は欧米式で異性愛の画像になりやすい。医者の画像は白人男性になりやすい、他人の著作物をアップロードしない）。\n",
        "* 他者の権利を侵害しない（孫悟空やダースベイダーなどを意図的に作らない）。\n",
        "* 実材の人物、事件、イベントの画像（フェイクニュース含む）を作成しない。\n",
        "* 現役の作家の画風を単独指名で入力しない（個人的に推奨のマナーです）。\n",
        "\n",
        "----\n",
        "\n",
        "## お願い\n",
        "AIによる画像生成、仕事がなくなるといった文脈で煽る方向の流れは、望むものではありません。\n",
        "むしろ、みんなで「新しい創作」はどういうものか？アーティストはどうAIを使いこなしていけばいいのか？を模索していければお思います。 \n",
        "\n",
        "活版印刷が著作権の概念を生み、写真が印象派や抽象芸術の扉を開いたように、新しいテクノロジーは、新しい表現をもたらします。今、必要なことは、みんなであらゆる方向から実験をして、新しい可能性の総当たり探索をすることだと思います。\n",
        "\n",
        "そんな方向性で使ってもらえればと。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9MvuOa_Bg9H"
      },
      "source": [
        "## 謝辞\n",
        "構成コードは以下の方々のライブラリ、スニペット、コードを参考、あるいは依拠しています。\n",
        "またnotebookは下記コード群のライセンスを継承します。\n",
        "\n",
        "* [StableDiffusion](https://github.com/CompVis/stable-diffusion) - [CreativeML Open RAIL-M License](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)\n",
        "* [Diffusers](https://github.com/huggingface/diffusers) - [Apache License 2.0](https://github.com/huggingface/diffusers/blob/main/LICENSE)\n",
        "* KLMSサンプリングは、[@RiversHaveWings](https://twitter.com/RiversHaveWings) 氏の [KLMS Sampling](https://github.com/crowsonkb/k-diffusion.git)より。 [MIT License](https://github.com/crowsonkb/k-diffusion/blob/master/LICENSE)\n",
        "* プロンプトのウェイト処理は、[@Lincoln Stein](https://github.com/lstein)氏のカスタム版[StableDiffusion](https://github.com/lstein/stable-diffusion)より。 [MIT LICENSE](https://github.com/lstein/stable-diffusion/blob/main/LICENSE)\n",
        "* KLMS連携の理解に [@pharmapsychotic](https://twitter.com/pharmapsychotic)氏の[Stable Diffusion notebook](https://colab.research.google.com/github/pharmapsychotic/ai-notebooks/blob/main/pharmapsychotic_Stable_Diffusion.ipynb#scrollTo=UU52ZvES6-1T)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q9zaq2YG9Gv"
      },
      "source": [
        "## 更新履歴\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3EqPl-NQCtM"
      },
      "source": [
        "* 20220904: TextInversionで作成したembedding.ptファイルに対応\n",
        "* タイルパターンモードに対応\n",
        "* セーフフィルタのリックおじさんを空白画像に差し替え\n",
        "* プロンプトにMidJourney風ウェイト処理を追加。「dog::5 cat::3」などとできる。\n",
        "* DiffuserベースだとImg2Imgが限定的だったので、Diffuserやめる。\n",
        "* Gradioで最低限のGUIをつける"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYSWe7iUKRc9"
      },
      "source": [
        "# セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcGfQNeFPP6h",
        "outputId": "9ae8b4ee-4afb-4bbf-b9e0-7bb2dd3291ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## 1-1. Google Driveのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9RQ_rTSiMPpr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## 1-2. Google Driveにアップしたモデルのパスを設定\n",
        "#@markdown 左メニューからGoogle Driveを掘り、アップロードしたckptファイルを選択し、右クリックから「パスをコピー」を行います。\n",
        "#@markdown コピーしたパスを下のフォームにコピペしてください。\n",
        "\n",
        "GDRIVE_MODEL_PATH = \"/content/drive/MyDrive/stable-diffusion/sd-v1-4.ckpt\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I54Hq4Ce7ddY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## 1-3. 画像の保存設定\n",
        "DRIVE_PATH = \"/content/drive/MyDrive\" #Driveのルート\n",
        "SAVE_FILE = True #@param {type:\"boolean\"}\n",
        "SAVE_FILE_PATH = \"/content/drive/MyDrive/stable-diffusion/output\" #@param {type:\"string\"}\n",
        "SAVE_FILE_PREFIX = \"SD\" #@param {type:\"string\"}\n",
        "\n",
        "#タイルモード記憶変数\n",
        "tile_mode_init_Conv2d = None\n",
        "tile_mode_init_ConvTranspose2d = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc5OwvKdjRJF",
        "outputId": "49fbeb52-283b-4cc8-8b4f-3d288597c435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-3cd4f7fd-ab56-23a9-5205-556225606392)\n"
          ]
        }
      ],
      "source": [
        "#GPUの確認\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_u08HhXKZdq"
      },
      "outputs": [],
      "source": [
        "#必要ファイルのインストール\n",
        "%cd /content/\n",
        "\n",
        "#GIT\n",
        "!git clone https://github.com/CompVis/stable-diffusion  \n",
        "%cd /content/stable-diffusion\n",
        "\n",
        "!git clone https://github.com/CompVis/taming-transformers\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "!git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "\n",
        "#PIP\n",
        "!pip install albumentations \n",
        "!pip install diffusers==0.2.4 \n",
        "!pip install gradio \n",
        "!pip install numpy einops kornia\n",
        "!pip install omegaconf\n",
        "!pip install pytorch-lightning\n",
        "!pip install torch-fidelity\n",
        "!pip install transformers\n",
        "!pip install ftfy jsonmerge resize-right torchdiffeq tqdm\n",
        "\n",
        "#Pathを通す\n",
        "import sys\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"./CLIP\")\n",
        "sys.path.append('./taming-transformers')\n",
        "sys.path.append('./k-diffusion')\n",
        "sys.path.append('./ldm')\n",
        "\n",
        "#k_diffusionは初期化が必要\n",
        "!echo '' > ./k-diffusion/k_diffusion/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DCfyEcERiwPF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "#@markdown # タイルモードのオンオフ\n",
        "#@markdown 作成する画像をループするタイル画像にします。この設定を変えた場合、ここから下のセルを全て実行しなおす必要があります。\n",
        "\n",
        "#klassの__init__をいったん退避\n",
        "#新しい__init__を定義\n",
        "\n",
        "# code by lox9973\n",
        "# https://gitlab.com/-/snippets/2395088\n",
        "\n",
        "tile_mode = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#オリジナルのConvの初期化関数を保存\n",
        "if tile_mode_init_Conv2d == None:\n",
        "  tile_mode_init_Conv2d = torch.nn.Conv2d.__init__\n",
        "  tile_mode_init_ConvTranspose2d = torch.nn.ConvTranspose2d.__init__\n",
        "\n",
        "\n",
        "def activate_tile_mode():\n",
        "  if torch.nn.Conv2d.__init__ != tile_mode_init_Conv2d:\n",
        "    return\n",
        "\n",
        "  for klass in [torch.nn.Conv2d, torch.nn.ConvTranspose2d]:\n",
        "      patch_conv(klass)\n",
        "  tile_mode = True\n",
        "  print(\"tile mode activated\")\n",
        "\n",
        "\n",
        "#Conv Filterの復元\n",
        "def deactivate_tile_mode():\n",
        "  if torch.nn.Conv2d.__init__ == tile_mode_init_Conv2d:\n",
        "    return\n",
        "  torch.nn.Conv2d.__init__ = tile_mode_init_Conv2d\n",
        "  torch.nn.ConvTranspose2d.__init__ = tile_mode_init_ConvTranspose2d\n",
        "  tile_mode == False\n",
        "  print(\"tile mode deactivated\")\n",
        "\n",
        "def patch_conv(klass):\n",
        "\tinit = klass.__init__\n",
        "\tdef __init__(self, *args, **kwargs):\n",
        "\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\tklass.__init__ = __init__\n",
        "\n",
        "if tile_mode == True:\n",
        "  activate_tile_mode()\n",
        "else:\n",
        "  deactivate_tile_mode()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bcHsbr3hblrk",
        "outputId": "9cba86ee-5fab-444e-f7dc-5d3c8058a710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32ff9686a7ee42489c32ad1e771227f9",
            "d3d0339b78cd40fbba01f41e87b2f479",
            "f7cd77ae92c641e88ff8cf2b6d675537",
            "9d0d939c6d0b44d0bd63d9ecee5261ea",
            "22bc359153ce467d930e39175f467523",
            "bcbea526a7734b93b1e5af1b98323978",
            "464861d3607f4ecda8bc9f1de2c9ecfd",
            "d87613cd6e444d30bdd784dbca48e53d",
            "f77d64695f194b799f2e120f5a16c41d",
            "e02485fbc5f9435c943983e4412b2de4",
            "b731e4d2020c4fe6ad793730e0672963",
            "de4008b11cad43699e35a0913bc6920b",
            "a993503d338e4fa88adb7c1e30d178a0",
            "08b7128b2f734f74a19d8420b3d4df99",
            "73a1433642ac4a5286ba258e697e8d6b",
            "88f5ab3ed3154bedb33ba4d777d82553",
            "fd99a6dea052441d8f2eee19825c0357",
            "563efbad730947c4b64f9ebfe7744586",
            "f8c0bdc57e914547b01f0a089528a898",
            "d49d0981679946dbb9ea749cc234d626",
            "401353b5b3c54fdb8ca9a5997e6d0f64",
            "e326f0de600645529ad890387928f70a",
            "37a00b7230a9494ea6221513d9308b3d",
            "69a49e745f9040ab85620cd066f092b1",
            "a4b22f4a545c4beeaf4f0e7f55f9f230",
            "7c123bab34d0454893e78812bf0f20eb",
            "0e5efc2c733349abb2edd8d123ca3242",
            "af98f1a3e1704caea837b0bd46ccfcb5",
            "9f6445d10fe546f68e6fcea6898a283c",
            "a396cae3565845bdbf3a60b7ef924453",
            "96ee7592018b459192181937449b9218",
            "71e71c214e144cdca4b710f653fc5767",
            "1630d79a17e94066b15c8ede20e04df4",
            "77ec72be01a9420f87904715b7da07df",
            "5e228e5376b842d2b884bda95b344913",
            "06f09f03f43d4a55968a3385271ea456",
            "dea106d8323a48739954069f9e0d286e",
            "b1eb8a70babc48b4bbd682a497241a21",
            "d65eb61769ac4352888e7bd83c1bd617",
            "8e3539b502994fe8b3866bfa0612d805",
            "322b3871c24c4c1cab939f0d2131ba35",
            "2df6fc6828204c2ab4994d57c33b2172",
            "b8ae0639bc2f449e92479891b3bb4cfa",
            "71e062b60e1f4175a7d831967e0a11b9",
            "f619c3b3e6c04a988e02ce9522f1c9df",
            "a30704611bcd4106966c752a965279f9",
            "a06e0d92011c41c7bce17ac0032ca83e",
            "f1e8e841c02e422f8a01617133dd3653",
            "69c3f695701941c48776f6cf37c16b5d",
            "fe82dedaacd944e68fe01a075152185c",
            "62adcbc95f9340c6b09ec99aa7e1d1e0",
            "5b204eefe3ad4acd93f0339ce8b9bcd1",
            "1929f591bdc1459c8196ff3484503dff",
            "1e94a81d49a94831ab382ef3684dac42",
            "eab4c05f29224d7ca9427a3ea52ee301",
            "f506e0f5b35349dd9669d2f392461e8c",
            "a109948ec7304fc58415bf59bffc41f2",
            "b6692798177145f4b940933e3edfae75",
            "83ecc0e87811439e9d57d6cf508778df",
            "d8fb5c3f0e2a4ba6928cce0af5f40de4",
            "7345d072b8b449a4b61924fe17847010",
            "5647da50934b4227a915f5970a3eb09a",
            "68a8e8998a3c476f9ac606a6e2575cd7",
            "e36c829a1ced46fcba6932aca56b864c",
            "92b9d89fe2514a1fb47ee63c4551f878",
            "59b8521a8d7947cd8b358a95b4266a4b",
            "1cf3c48ad2b146fcb9a912d3aa976694",
            "a9d0dec94b2342af81c3ccdad856df3a",
            "55f783d8783d4a1fb51f645b800f76b3",
            "7850c5815a6c4600b9b58edc7de4a173",
            "bceedab559654baf99a0d78b57e33753",
            "d15ee1d576c54a9c8cfbb48b06f27b36",
            "6c153cd22b3f42e3892e7cabdb534a86",
            "0812b4aace38439ca511943e98f0e824",
            "e7c5a1c7593c4d32ac50a70020b3526a",
            "0f2f06738d424fcb963e42b23cceb2c4",
            "31ade7a1b503438cb01a70332e640b1e",
            "2504e2eebc944ec3a8bbc9bc8a26ca6c",
            "a5e1f5821da8439aa94e6bbe768b6ee2",
            "d626e31f13b443518d5fbaeeb1475b42",
            "e8c5c6595afb4416addd7e9e5cc3c899",
            "636c4b7c85144ccf87cde22dee54afc5",
            "7cc8929a8b9c49299020595166430246",
            "b273c9cf6118474ba45c4fdb34ef714d",
            "743a7ebb065c49b989c384b9c3a03542",
            "c47139ff03b94ab4a785347c3953edca",
            "ac303bda3c534deab83738310aae0c5a",
            "1e8b8fa5bcdf49df99fd342f29b7254a",
            "95e1857b6f924bf39c3e06581c97a6c9",
            "5726a70aaafd4a009308224b32b78905",
            "bbf2d12b5f5247a1941debbaa019f1d4",
            "83a96d7923a84f31b8df24d46019ae40",
            "0b7a3c0a241d4c10bc327221832d13f5",
            "838bda2e09984ac3bad418167dacc504",
            "e639f442e21e45d9adf554a1064fe8d1",
            "158cd6311d1d440997624992ccb7ef5c",
            "c2599c318715457081d6050750f1878f",
            "9aea8fb1bb1f4ca0a4a1596642220b4d",
            "75530fe9ed514fcc9a58889341abca7d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/stable-diffusion/sd-v1-4.ckpt\n",
            "Global Step: 470000\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/939k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32ff9686a7ee42489c32ad1e771227f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/512k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de4008b11cad43699e35a0913bc6920b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37a00b7230a9494ea6221513d9308b3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77ec72be01a9420f87904715b7da07df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f619c3b3e6c04a988e02ce9522f1c9df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.59G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f506e0f5b35349dd9669d2f392461e8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.weight', 'text_projection.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'visual_projection.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'logit_scale', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cf3c48ad2b146fcb9a912d3aa976694"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/4.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2504e2eebc944ec3a8bbc9bc8a26ca6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95e1857b6f924bf39c3e06581c97a6c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentDiffusion(\n",
            "  (model): DiffusionWrapper(\n",
            "    (diffusion_model): UNetModel(\n",
            "      (time_embed): Sequential(\n",
            "        (0): Linear(in_features=320, out_features=1280, bias=True)\n",
            "        (1): SiLU()\n",
            "        (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "      )\n",
            "      (input_blocks): ModuleList(\n",
            "        (0): TimestepEmbedSequential(\n",
            "          (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (1): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (2): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (3): TimestepEmbedSequential(\n",
            "          (0): Downsample(\n",
            "            (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (4): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (5): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (6): TimestepEmbedSequential(\n",
            "          (0): Downsample(\n",
            "            (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (7): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (8): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (9): TimestepEmbedSequential(\n",
            "          (0): Downsample(\n",
            "            (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (10): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "        )\n",
            "        (11): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (middle_block): TimestepEmbedSequential(\n",
            "        (0): ResBlock(\n",
            "          (in_layers): Sequential(\n",
            "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "            (1): SiLU()\n",
            "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (h_upd): Identity()\n",
            "          (x_upd): Identity()\n",
            "          (emb_layers): Sequential(\n",
            "            (0): SiLU()\n",
            "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (out_layers): Sequential(\n",
            "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "            (1): SiLU()\n",
            "            (2): Dropout(p=0, inplace=False)\n",
            "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (skip_connection): Identity()\n",
            "        )\n",
            "        (1): SpatialTransformer(\n",
            "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (transformer_blocks): ModuleList(\n",
            "            (0): BasicTransformerBlock(\n",
            "              (attn1): CrossAttention(\n",
            "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_out): Sequential(\n",
            "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (ff): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): GEGLU(\n",
            "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                  )\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                )\n",
            "              )\n",
            "              (attn2): CrossAttention(\n",
            "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                (to_out): Sequential(\n",
            "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  (1): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): ResBlock(\n",
            "          (in_layers): Sequential(\n",
            "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "            (1): SiLU()\n",
            "            (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (h_upd): Identity()\n",
            "          (x_upd): Identity()\n",
            "          (emb_layers): Sequential(\n",
            "            (0): SiLU()\n",
            "            (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (out_layers): Sequential(\n",
            "            (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "            (1): SiLU()\n",
            "            (2): Dropout(p=0, inplace=False)\n",
            "            (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (skip_connection): Identity()\n",
            "        )\n",
            "      )\n",
            "      (output_blocks): ModuleList(\n",
            "        (0): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (1): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (2): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Upsample(\n",
            "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (3): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (4): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (5): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Upsample(\n",
            "            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (6): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (7): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (8): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Upsample(\n",
            "            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (9): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (10): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (11): TimestepEmbedSequential(\n",
            "          (0): ResBlock(\n",
            "            (in_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (h_upd): Identity()\n",
            "            (x_upd): Identity()\n",
            "            (emb_layers): Sequential(\n",
            "              (0): SiLU()\n",
            "              (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "            )\n",
            "            (out_layers): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Dropout(p=0, inplace=False)\n",
            "              (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): SpatialTransformer(\n",
            "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (transformer_blocks): ModuleList(\n",
            "              (0): BasicTransformerBlock(\n",
            "                (attn1): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (ff): FeedForward(\n",
            "                  (net): Sequential(\n",
            "                    (0): GEGLU(\n",
            "                      (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                    )\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                    (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                )\n",
            "                (attn2): CrossAttention(\n",
            "                  (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                  (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                  (to_out): Sequential(\n",
            "                    (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                    (1): Dropout(p=0.0, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "              )\n",
            "            )\n",
            "            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (out): Sequential(\n",
            "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "        (1): SiLU()\n",
            "        (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (first_stage_model): AutoencoderKL(\n",
            "    (encoder): Encoder(\n",
            "      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (down): ModuleList(\n",
            "        (0): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (downsample): Downsample(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "          )\n",
            "        )\n",
            "        (1): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (downsample): Downsample(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "          )\n",
            "        )\n",
            "        (2): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (downsample): Downsample(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "          )\n",
            "        )\n",
            "        (3): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "        )\n",
            "      )\n",
            "      (mid): Module(\n",
            "        (block_1): ResnetBlock(\n",
            "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (attn_1): AttnBlock(\n",
            "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (block_2): ResnetBlock(\n",
            "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (decoder): Decoder(\n",
            "      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mid): Module(\n",
            "        (block_1): ResnetBlock(\n",
            "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "        (attn_1): AttnBlock(\n",
            "          (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (block_2): ResnetBlock(\n",
            "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "          (dropout): Dropout(p=0.0, inplace=False)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (up): ModuleList(\n",
            "        (0): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "        )\n",
            "        (1): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (upsample): Upsample(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (2): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (upsample): Upsample(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (3): Module(\n",
            "          (block): ModuleList(\n",
            "            (0): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (1): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "            (2): ResnetBlock(\n",
            "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (attn): ModuleList()\n",
            "          (upsample): Upsample(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (loss): Identity()\n",
            "    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (cond_stage_model): FrozenCLIPEmbedder(\n",
            "    (transformer): CLIPTextModel(\n",
            "      (text_model): CLIPTextTransformer(\n",
            "        (embeddings): CLIPTextEmbeddings(\n",
            "          (token_embedding): Embedding(49408, 768)\n",
            "          (position_embedding): Embedding(77, 768)\n",
            "        )\n",
            "        (encoder): CLIPEncoder(\n",
            "          (layers): ModuleList(\n",
            "            (0): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (1): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (2): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (3): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (4): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (5): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (6): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (7): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (8): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (9): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (10): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "            (11): CLIPEncoderLayer(\n",
            "              (self_attn): CLIPAttention(\n",
            "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (mlp): CLIPMLP(\n",
            "                (activation_fn): QuickGELUActivation()\n",
            "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              )\n",
            "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Warning: Model does not have embedding_manager\n"
          ]
        }
      ],
      "source": [
        "import argparse, gc, json, os, random, sys, time, glob, requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import PIL\n",
        "from contextlib import contextmanager, nullcontext\n",
        "from einops import rearrange, repeat\n",
        "from IPython.display import display, clear_output\n",
        "from itertools import islice\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from pytorch_lightning import seed_everything\n",
        "from torch.cuda.amp import autocast\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "\n",
        "from k_diffusion.sampling import sample_lms\n",
        "from k_diffusion.external import CompVisDenoiser\n",
        "\n",
        "from diffusers.pipelines.stable_diffusion.safety_checker import StableDiffusionSafetyChecker\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "from datetime import datetime\n",
        "import gc\n",
        "\n",
        "#メモリのクリーンアップ\n",
        "def clear_memory():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache() \n",
        "\n",
        "\n",
        "#新しいDenoiser\n",
        "class CFGDenoiser(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.inner_model = model\n",
        "\n",
        "    def forward(self, x, sigma, uncond, cond, cond_scale):\n",
        "        x_in = torch.cat([x] * 2)\n",
        "        sigma_in = torch.cat([sigma] * 2)\n",
        "        cond_in = torch.cat([uncond, cond])\n",
        "        uncond, cond = self.inner_model(x_in, sigma_in, cond=cond_in).chunk(2)\n",
        "        return uncond + (cond - uncond) * cond_scale\n",
        "\n",
        "\n",
        "#Config用クラス\n",
        "class SDOption():\n",
        "  def __init__(self):\n",
        "    self.ckpt = GDRIVE_MODEL_PATH\n",
        "    self.config = 'configs/stable-diffusion/v1-inference.yaml'\n",
        "    self.ddim_eta = 0.0\n",
        "    self.ddim_steps = 50\n",
        "    self.embedding = None # TextInversion対応用のEmbedding.pyファイルへのパス\n",
        "    self.fixed_code = True\n",
        "    self.init_img = None\n",
        "    self.init_mask = None\n",
        "    self.n_iter = 1\n",
        "    self.n_samples = 1\n",
        "    self.outdir = SAVE_FILE_PATH\n",
        "    self.precision = 'full' # 'autocast'\n",
        "    self.prompt = \"\"\n",
        "    self.sampler = 'klms'\n",
        "    self.save = True\n",
        "    self.scale = 7.5\n",
        "    self.seed = -1\n",
        "    self.strength = 0.5\n",
        "    self.variations_mode = True #Export variations of init Image\n",
        "    self.H = 512\n",
        "    self.W = 512\n",
        "    self.C = 4\n",
        "    self.f = 8\n",
        "\n",
        "\n",
        "#第3パラメーターにEmbeddingPath（Text InversionでトレーニングしたTextEmbedderを指定可能に）\n",
        "class SDHelper():\n",
        "  def __init__(self, config_path, model_path, embedding_path = None):\n",
        "    config = OmegaConf.load(config_path)\n",
        "    self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    self.model = self.load_model_from_config(config, model_path).to(self.device)\n",
        "    self.safety_model_id = \"CompVis/stable-diffusion-safety-checker\"\n",
        "    self.safety_feature_extractor = AutoFeatureExtractor.from_pretrained(self.safety_model_id)\n",
        "    self.safety_checker = StableDiffusionSafetyChecker.from_pretrained(self.safety_model_id)\n",
        "\n",
        "    if embedding_path != None:\n",
        "      if hasattr(self.model, \"embedding_manager\"):\n",
        "        self.model.embedding_manager.load(embedding_path)\n",
        "      else:\n",
        "        print(\"Warning: Model does not have embedding_manager\")\n",
        "\n",
        "\n",
        "  def chunk(self, it, size):\n",
        "      it = iter(it)\n",
        "      return iter(lambda: tuple(islice(it, size)), ())\n",
        "\n",
        "\n",
        "  def load_model_from_config(self, config, ckpt, verbose=False):\n",
        "      print(f\"Loading model from {ckpt}\")\n",
        "      pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
        "      if \"global_step\" in pl_sd:\n",
        "          print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "      sd = pl_sd[\"state_dict\"]\n",
        "      model = instantiate_from_config(config.model)\n",
        "      m, u = model.load_state_dict(sd, strict=False)\n",
        "      if len(m) > 0 and verbose:\n",
        "          print(\"missing keys:\")\n",
        "          print(m)\n",
        "      if len(u) > 0 and verbose:\n",
        "          print(\"unexpected keys:\")\n",
        "          print(u)\n",
        "\n",
        "      model.cuda()\n",
        "      model.eval()\n",
        "      return model\n",
        "\n",
        "  def make_batch(self, image, mask):\n",
        "      image = np.array(Image.open(image).convert(\"RGB\"))\n",
        "      image = image.astype(np.float32)/255.0\n",
        "      image = image[None].transpose(0,3,1,2)\n",
        "      image = torch.from_numpy(image)\n",
        "\n",
        "      mask = np.array(Image.open(mask).convert(\"L\"))\n",
        "      mask = mask.astype(np.float32)/255.0\n",
        "      mask = mask[None,None]\n",
        "      mask[mask < 0.5] = 0\n",
        "      mask[mask >= 0.5] = 1\n",
        "      mask = torch.from_numpy(mask)\n",
        "\n",
        "      masked_image = (1-mask)*image\n",
        "\n",
        "      batch = {\"image\": image, \"mask\": mask, \"masked_image\": masked_image}\n",
        "      for k in batch:\n",
        "          batch[k] = batch[k].to(device=self.device)\n",
        "          batch[k] = batch[k]*2.0-1.0\n",
        "      return batch\n",
        "\n",
        "\n",
        "  def load_img(self, path, w, h):\n",
        "    if path.startswith('http://') or path.startswith('https://'):\n",
        "        image = Image.open(requests.get(path, stream=True).raw).convert('RGB')\n",
        "    else:\n",
        "        if os.path.isdir(path):\n",
        "            files = [file for file in os.listdir(path) if file.endswith('.png') or file .endswith('.jpg')]\n",
        "            path = os.path.join(path, random.choice(files))\n",
        "            print(f\"Chose random init image {path}\")\n",
        "        image = Image.open(path).convert('RGB')\n",
        "    image = image.resize((w, h), Image.LANCZOS)\n",
        "    w, h = image.size\n",
        "    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
        "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "    image = image[None].transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return 2.*image - 1.\n",
        "\n",
        "\n",
        "  def numpy_to_pil(self, images):\n",
        "    if images.ndim == 3:\n",
        "        images = images[None, ...]\n",
        "    images = (images * 255).round().astype(\"uint8\")\n",
        "    pil_images = [Image.fromarray(image) for image in images]\n",
        "    return pil_images\n",
        "\n",
        "\n",
        "  def load_replacement(self, x):\n",
        "      try:\n",
        "          hwc = x.shape\n",
        "          #セーフフィルターのリック・ストレイは、日本では法律に触れる可能性があるので、違う画像に差し替えます。\n",
        "          #y = Image.open(\"assets/rick.jpeg\").convert(\"RGB\").resize((hwc[1], hwc[0]))\n",
        "          y = PIL.Image.new(mode=\"RGB\", size=(hwc[1], hwc[0]))\n",
        "          y = (np.array(y)/255.0).astype(x.dtype)\n",
        "          assert y.shape == x.shape\n",
        "          return y\n",
        "      except Exception:\n",
        "          return x\n",
        "\n",
        "\n",
        "  def check_safety(self, x_image):\n",
        "    safety_checker_input = self.safety_feature_extractor(self.numpy_to_pil(x_image), return_tensors=\"pt\")\n",
        "    x_checked_image, has_nsfw_concept = self.safety_checker(images=x_image, clip_input=safety_checker_input.pixel_values)\n",
        "    assert x_checked_image.shape[0] == len(has_nsfw_concept)\n",
        "    for i in range(len(has_nsfw_concept)):\n",
        "        if has_nsfw_concept[i]:\n",
        "            x_checked_image[i] = self.load_replacement(x_checked_image[i])\n",
        "    return x_checked_image, has_nsfw_concept\n",
        "\n",
        "\n",
        "  def get_prompt_weight(self, prompt):\n",
        "    return self.model.get_learned_conditioning(prompt)\n",
        "    \n",
        "\n",
        "  def generate(self, opt):\n",
        "      global sample_idx\n",
        "      seed_everything(opt.seed)\n",
        "\n",
        "      #出力ディレクトリの作成\n",
        "      os.makedirs(opt.outdir, exist_ok=True)\n",
        "\n",
        "      #サンプラー選択\n",
        "      if opt.sampler == 'plms':\n",
        "          sampler = PLMSSampler(self.model)\n",
        "      else:\n",
        "          sampler = DDIMSampler(self.model)\n",
        "\n",
        "      model_wrap = CompVisDenoiser(self.model)       \n",
        "      batch_size = opt.n_samples\n",
        "\n",
        "      #promptをバッチの数だけコピー\n",
        "      prompt = opt.prompt\n",
        "      assert prompt is not None\n",
        "      data = [batch_size * [prompt]]\n",
        "\n",
        "\n",
        "      #初期画像の潜在空間を作成\n",
        "      init_latent = None\n",
        "      if opt.init_img != None and opt.init_img != '':\n",
        "          init_image = self.load_img(opt.init_img, opt.W, opt.H).to(self.device)\n",
        "          init_image = repeat(init_image, '1 ... -> b ...', b=batch_size)\n",
        "          init_latent = self.model.get_first_stage_encoding(self.model.encode_first_stage(init_image))  # move to latent space\n",
        "\n",
        "\n",
        "      #Inpaint用（つくりかけ）\n",
        "      \"\"\"\n",
        "      if opt.init_mask != None:\n",
        "        init_image = self.load_img(opt.init_img, opt.W, opt.H).to(self.device)\n",
        "        init_mask = self.load_img(opt.init_mask, opt.W, opt.H).to(self.device)\n",
        "        init_masked_image = (1-init_mask)*init_image\n",
        "        batch = {\"image\": init_image, \"mask\": init_mask, \"masked_image\": init_masked_image}\"\"\"\n",
        "\n",
        "      sampler.make_schedule(ddim_num_steps=opt.ddim_steps, ddim_eta=opt.ddim_eta, verbose=False)\n",
        "      t_enc = int(opt.strength * opt.ddim_steps)\n",
        "\n",
        "\n",
        "      #?? txt2imgで使われる初期値っぽいが…？\n",
        "      start_code = None\n",
        "      if opt.fixed_code and init_latent == None:\n",
        "          start_code = torch.randn([opt.n_samples, opt.C, opt.H // opt.f, opt.W // opt.f], device=self.device)\n",
        "\n",
        "      precision_scope = autocast if opt.precision == \"autocast\" else nullcontext\n",
        "\n",
        "      images = []\n",
        "      with torch.no_grad():\n",
        "          with precision_scope(\"cuda\"):\n",
        "              with self.model.ema_scope():\n",
        "                  for n in range(opt.n_iter):\n",
        "                      for prompts in data:\n",
        "                          #init_latentに初期画像の潜在空間\n",
        "                          #cにコンディショナル条件の潜在空間\n",
        "                          #ucにあんコンディショナルの潜在\n",
        "\n",
        "                          uc = None\n",
        "                          if opt.scale != 1.0:\n",
        "                              uc = self.model.get_learned_conditioning(batch_size * [\"\"])\n",
        "\n",
        "                          if isinstance(prompts, tuple):\n",
        "                              prompts = list(prompts)\n",
        "\n",
        "                          #プロンプトのウェイト処理\n",
        "                          #全てのプロンプトに正規化したウェイトをかけて合算する\n",
        "                          subprompts, weights = SDHelper.prompt_splitter(prompts[0])\n",
        "                          if len(subprompts) > 1:\n",
        "                            c = torch.zeros_like(uc)\n",
        "                            # get total weight for normalizing\n",
        "                            totalWeight = sum(weights)\n",
        "                            # normalize each \"sub prompt\" and add it\n",
        "                            for i in range(0,len(subprompts)):\n",
        "                              weight = weights[i]\n",
        "                              #if not skip_normalize:\n",
        "                              # skip_normalizeがついてる意図が不明なので外す。\n",
        "                              weight = weight / totalWeight\n",
        "                              c = torch.add(c,self.model.get_learned_conditioning(subprompts[i]), alpha=weight)\n",
        "                          else: # just standard prompt\n",
        "                            c = self.model.get_learned_conditioning(prompts)\n",
        "\n",
        "\n",
        "                          if init_latent != None:\n",
        "                              #Img2Ima\n",
        "                              \n",
        "                              #z_enc に 初期画像の潜在空間\n",
        "                              #cにテキストの潜在空間\n",
        "                              #t_encに 画像のstrength * ddimsteps?\n",
        "                              #ucに空白\n",
        "                              z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(self.device))\n",
        "                              samples = sampler.decode(z_enc, \n",
        "                                                       c, \n",
        "                                                       t_enc, \n",
        "                                                       unconditional_guidance_scale=opt.scale,\n",
        "                                                       unconditional_conditioning=uc)\n",
        "                          else:\n",
        "                              if opt.sampler == 'klms':\n",
        "                                  print(\"Using KLMS sampling\")\n",
        "                                  shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n",
        "                                  sigmas = model_wrap.get_sigmas(opt.ddim_steps)\n",
        "                                  model_wrap_cfg = CFGDenoiser(model_wrap)\n",
        "                                  x = torch.randn([opt.n_samples, *shape], device=self.device) * sigmas[0]\n",
        "                                  extra_args = {'cond': c, 'uncond': uc, 'cond_scale': opt.scale}\n",
        "                                  samples = sample_lms(model_wrap_cfg, \n",
        "                                                       x, \n",
        "                                                       sigmas, \n",
        "                                                       extra_args=extra_args, \n",
        "                                                       disable=False)\n",
        "                              else:\n",
        "                                  shape = [opt.C, opt.H // opt.f, opt.W // opt.f]\n",
        "                                  samples, _ = sampler.sample(S=opt.ddim_steps,\n",
        "                                                                  conditioning=c,\n",
        "                                                                  batch_size=opt.n_samples,\n",
        "                                                                  shape=shape,\n",
        "                                                                  verbose=False,\n",
        "                                                                  unconditional_guidance_scale=opt.scale,\n",
        "                                                                  unconditional_conditioning=uc,\n",
        "                                                                  eta=opt.ddim_eta,\n",
        "                                                                  x_T=start_code)\n",
        "\n",
        "                          x_samples = self.model.decode_first_stage(samples)\n",
        "                          x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "                          x_samples = x_samples.cpu().permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "                          #Safety Checker added\n",
        "                          x_checked_image, has_nsfw_concept = self.check_safety(x_samples)\n",
        "                          x_checked_image_torch = torch.from_numpy(x_checked_image).permute(0, 3, 1, 2)\n",
        "\n",
        "                          for x_sample in x_checked_image_torch:\n",
        "                            x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
        "                            images.append(Image.fromarray(x_sample.astype(np.uint8)))\n",
        "                            if (opt.save==True):\n",
        "                              file_id = datetime.today().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "                              filepath = os.path.join(opt.outdir, f\"{SAVE_FILE_PREFIX}-{file_id}.png\")\n",
        "                              Image.fromarray(x_sample.astype(np.uint8)).save(filepath)\n",
        "                              #sample_idx += 1\n",
        "      return images\n",
        "\n",
        "  #Prompt Splitter is based on Lincoln Stein's code\n",
        "  #https://github.com/lstein/stable-diffusion/blob/main/ldm/simplet2i.py\n",
        "\n",
        "  #MidJourney互換でプロンプトの重さを処理するコード\n",
        "  #任意の文字列、 :: （スペース入るかも）（数字はいるかも）　（スペース入るかも）\n",
        "  def prompt_splitter(text):\n",
        "    \"\"\"\n",
        "    grabs all text up to the first occurrence of ':' \n",
        "    uses the grabbed text as a sub-prompt, and takes the value following ':' as weight\n",
        "    if ':' has no value defined, defaults to 1.0\n",
        "    repeats until no text remaining\n",
        "    \"\"\"\n",
        "    remaining = len(text)\n",
        "    prompts = []\n",
        "    weights = []\n",
        "    while remaining > 0:\n",
        "        if \"::\" in text:\n",
        "            idx = text.index(\"::\") # first occurrence from start\n",
        "            # grab up to index as sub-prompt\n",
        "            prompt = text[:idx]\n",
        "            remaining -= idx\n",
        "            # remove from main text\n",
        "            text = text[idx+2:]\n",
        "            # find value for weight \n",
        "            if \" \" in text:\n",
        "                idx = text.index(\" \") # first occurence\n",
        "            else: # no space, read to end\n",
        "                idx = len(text)\n",
        "            if idx != 0:\n",
        "                try:\n",
        "                    weight = float(text[:idx])\n",
        "                except: # couldn't treat as float\n",
        "                    print(f\"Warning: '{text[:idx]}' is not a value, are you missing a space?\")\n",
        "                    weight = 1.0\n",
        "            else: # no value found\n",
        "                weight = 1.0\n",
        "            # remove from main text\n",
        "            remaining -= idx\n",
        "            text = text[idx+1:]\n",
        "            # append the sub-prompt and its weight\n",
        "            prompts.append(prompt)\n",
        "            weights.append(weight)\n",
        "        else: # no : found\n",
        "            if len(text) > 0: # there is still text though\n",
        "                # take remainder as weight 1\n",
        "                prompts.append(text)\n",
        "                weights.append(1.0)\n",
        "            remaining = 0\n",
        "    print(prompts)\n",
        "    print(weights)\n",
        "    return prompts, weights\n",
        "\n",
        "\n",
        "#SDHelperのインスタンス化\n",
        "#第3引数にEmbeddingの.ptを指定すれば、TextInversionに対応可能\n",
        "opt = SDOption()\n",
        "sdh = SDHelper(opt.config, opt.ckpt, \"/content/drive/MyDrive/stable-diffusion/embeddings_gs-40000.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDqgT459ioLA"
      },
      "source": [
        "# GUIを起動"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#バッチ処理用"
      ],
      "metadata": {
        "id": "OVu85-Gi2671"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Init Image: ベース画像（オプション）\n",
        "* Prompt: 生成用のテキスト\n",
        "* Width: 幅\n",
        "* Height: 高さ\n",
        "* Cfg Scale: テキスト誘導の強さ（初期値 7.5)\n",
        "* Steps: 画像の描き込み時間。多いほど時間がかかり詳細になる。(初期値 50）\n",
        "* Init Image Strength: ベース画像をどれほど残すか（0: 無視 〜 1: 何もしない）\n",
        "* Num: 1回に生成する枚数\n",
        "* Seed: 画像の生成元となる乱数（-1にすると毎回ランダム）"
      ],
      "metadata": {
        "id": "LoIRg5p1KYR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w-cJQ8a1Q7ZL",
        "outputId": "2acf968d-2ef2-4881-9276-1645e1e99351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7ef9f8d93310>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://15889.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#GUIを起動\n",
        "import random\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "import re\n",
        "from PIL import Image, ImageFont, ImageDraw, ImageFilter, ImageOps\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import imageio\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "\n",
        "def diffuse(init_image, prompt, width, height, guidance_scale, steps, init_strength, num, seed):\n",
        "  result = list()\n",
        "  \"\"\"\n",
        "  if init_image != None:\n",
        "    imageio.imwrite(\"data.png\", init_image[\"image\"])\n",
        "    imageio.imwrite(\"data_mask.png\", init_image[\"mask\"]) \n",
        "    init_image = Image.open(\"data.png\")\n",
        "    mask_image = Image.open(\"data_mask.png\")\n",
        "    #display(init_image)\n",
        "    #display(mask_image)\n",
        "  \"\"\"\n",
        "    \n",
        "  opt.init_img = init_image \n",
        "  #init_image[\"image\"]\n",
        "  #opt.init_mask = init_image[\"mask\"]\n",
        "  opt.strength = 1- init_strength\n",
        "  opt.prompt = prompt\n",
        "  opt.W = width\n",
        "  opt.H = height\n",
        "  opt.scale = guidance_scale\n",
        "  opt.ddim_steps = steps\n",
        "  opt.n_iter = 1\n",
        "  opt.save == SAVE_FILE\n",
        "  \n",
        "  for index in range(int(num)):\n",
        "    opt.seed = random.randint(0, 2**32) if seed == -1 else seed\n",
        "    image = sdh.generate(opt)[0]\n",
        "    display(image)\n",
        "    result.append(image)\n",
        "  return result\n",
        "\n",
        "\n",
        "def image_clear(image_init, strength_sli):\n",
        "  print(\"image clear\", image_init)\n",
        "\n",
        "\n",
        "def image_change(image_init, strength_sli):\n",
        "  if image_init == None:\n",
        "    return gr.Slider.update(visible=False)\n",
        "  return gr.Slider.update(visible=True)\n",
        "\n",
        "\n",
        "def set_image_to_init(images):\n",
        "  if len(images)==0:\n",
        "    return\n",
        "  try:\n",
        "    image_data = re.sub('^data:image/.+;base64,', '', images[0])\n",
        "    image = Image.open(BytesIO(base64.b64decode(image_data)))\n",
        "    return image\n",
        "  except IndexError:\n",
        "    print(\"failed to get image\")\n",
        "    return\n",
        "  \n",
        "\n",
        "#GradioによるUI起動\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      with gr.Row():\n",
        "        prompt_txt = gr.Textbox(label=\"Prompt\", value=\"Beautiful detailing landscape oil painting of river and forest in the style of realism, perfect composition, golden hour\" )\n",
        "      with gr.Row():\n",
        "        with gr.Column():\n",
        "          init_img = gr.Image(value=None, source=\"upload\", interactive=True, tool=\"select\", type=\"filepath\", label=\"Init Image(option)\")\n",
        "          strength_sli = gr.Slider(label=\"Init Image Strength\", value=0.8, step=0.05, minimum=0.05, maximum=1, visible=False)\n",
        "\n",
        "      with gr.Row():\n",
        "        with gr.Column():\n",
        "          width_sli = gr.Slider(label=\"Width\", value=512, step=64, minimum=512, maximum=1024)\n",
        "          height_sli = gr.Slider(label=\"Height\", value=512, step=64, minimum=512, maximum=1024)\n",
        "          scale_sli = gr.Slider(label=\"Cfg Scale\", value=7.5, step=0.5, minimum=0, maximum=20)\n",
        "          steps_sli =gr.Slider(label=\"Steps\", value=50, step=10, minimum=10, maximum=300)\n",
        "        \n",
        "          num_num = gr.Number(label=\"Num\", value=1, minimum=1)\n",
        "          seed_num = gr.Number(label=\"Seed\", value=-1)\n",
        "          run_btn = gr.Button(\"Diffuse\", variant=\"Primary\")\n",
        "    with gr.Column():\n",
        "      gallery = gr.Gallery(elem_id=\"gallery\").style(height=\"640px\", container=True)\n",
        "      with gr.Row():\n",
        "        with gr.Column():\n",
        "          set_image_btn = gr.Button(\"Transfer to Init Image\").style(full_width=True)\n",
        "          run_btn.click(fn=diffuse, \n",
        "                        inputs=[init_img, prompt_txt, width_sli, height_sli, scale_sli, steps_sli, strength_sli, num_num, seed_num], \n",
        "                        outputs=[gallery])\n",
        "          \n",
        "          set_image_btn.click(fn=set_image_to_init, \n",
        "                    inputs=[gallery], \n",
        "                    outputs=[init_img])\n",
        "          \n",
        "          init_img.clear(fn=image_clear, inputs=[init_img, strength_sli], outputs=[strength_sli])\n",
        "          init_img.change(fn=image_change, inputs=[init_img, strength_sli], outputs=[strength_sli])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2つのPromptのブレンド\n",
        "\n",
        "prompt0 = \"Your Prompt Here\" #@param {type:\"string\"} \n",
        "prompt1 = \"Your Prompt2 Here\"  #@param {type:\"string\"} \n",
        "interpolation_step = 10 #param {type:\"integer\"}\n",
        "\n",
        "\n",
        "opt = SDOption()\n",
        "\n",
        "conditioning0 = sdh.get_prompt_weight(prompt0)\n",
        "conditioning1 = sdh.get_prompt_weight(prompt1)\n"
      ],
      "metadata": {
        "id": "k0lIBEVJpBXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32ff9686a7ee42489c32ad1e771227f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3d0339b78cd40fbba01f41e87b2f479",
              "IPY_MODEL_f7cd77ae92c641e88ff8cf2b6d675537",
              "IPY_MODEL_9d0d939c6d0b44d0bd63d9ecee5261ea"
            ],
            "layout": "IPY_MODEL_22bc359153ce467d930e39175f467523"
          }
        },
        "d3d0339b78cd40fbba01f41e87b2f479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbea526a7734b93b1e5af1b98323978",
            "placeholder": "​",
            "style": "IPY_MODEL_464861d3607f4ecda8bc9f1de2c9ecfd",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "f7cd77ae92c641e88ff8cf2b6d675537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87613cd6e444d30bdd784dbca48e53d",
            "max": 961143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f77d64695f194b799f2e120f5a16c41d",
            "value": 961143
          }
        },
        "9d0d939c6d0b44d0bd63d9ecee5261ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02485fbc5f9435c943983e4412b2de4",
            "placeholder": "​",
            "style": "IPY_MODEL_b731e4d2020c4fe6ad793730e0672963",
            "value": " 939k/939k [00:00&lt;00:00, 2.05MB/s]"
          }
        },
        "22bc359153ce467d930e39175f467523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbea526a7734b93b1e5af1b98323978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464861d3607f4ecda8bc9f1de2c9ecfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87613cd6e444d30bdd784dbca48e53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77d64695f194b799f2e120f5a16c41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02485fbc5f9435c943983e4412b2de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b731e4d2020c4fe6ad793730e0672963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4008b11cad43699e35a0913bc6920b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a993503d338e4fa88adb7c1e30d178a0",
              "IPY_MODEL_08b7128b2f734f74a19d8420b3d4df99",
              "IPY_MODEL_73a1433642ac4a5286ba258e697e8d6b"
            ],
            "layout": "IPY_MODEL_88f5ab3ed3154bedb33ba4d777d82553"
          }
        },
        "a993503d338e4fa88adb7c1e30d178a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd99a6dea052441d8f2eee19825c0357",
            "placeholder": "​",
            "style": "IPY_MODEL_563efbad730947c4b64f9ebfe7744586",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "08b7128b2f734f74a19d8420b3d4df99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c0bdc57e914547b01f0a089528a898",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d49d0981679946dbb9ea749cc234d626",
            "value": 524619
          }
        },
        "73a1433642ac4a5286ba258e697e8d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401353b5b3c54fdb8ca9a5997e6d0f64",
            "placeholder": "​",
            "style": "IPY_MODEL_e326f0de600645529ad890387928f70a",
            "value": " 512k/512k [00:00&lt;00:00, 652kB/s]"
          }
        },
        "88f5ab3ed3154bedb33ba4d777d82553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd99a6dea052441d8f2eee19825c0357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563efbad730947c4b64f9ebfe7744586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c0bdc57e914547b01f0a089528a898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49d0981679946dbb9ea749cc234d626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "401353b5b3c54fdb8ca9a5997e6d0f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e326f0de600645529ad890387928f70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37a00b7230a9494ea6221513d9308b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69a49e745f9040ab85620cd066f092b1",
              "IPY_MODEL_a4b22f4a545c4beeaf4f0e7f55f9f230",
              "IPY_MODEL_7c123bab34d0454893e78812bf0f20eb"
            ],
            "layout": "IPY_MODEL_0e5efc2c733349abb2edd8d123ca3242"
          }
        },
        "69a49e745f9040ab85620cd066f092b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af98f1a3e1704caea837b0bd46ccfcb5",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6445d10fe546f68e6fcea6898a283c",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "a4b22f4a545c4beeaf4f0e7f55f9f230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a396cae3565845bdbf3a60b7ef924453",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ee7592018b459192181937449b9218",
            "value": 389
          }
        },
        "7c123bab34d0454893e78812bf0f20eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e71c214e144cdca4b710f653fc5767",
            "placeholder": "​",
            "style": "IPY_MODEL_1630d79a17e94066b15c8ede20e04df4",
            "value": " 389/389 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "0e5efc2c733349abb2edd8d123ca3242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af98f1a3e1704caea837b0bd46ccfcb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6445d10fe546f68e6fcea6898a283c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a396cae3565845bdbf3a60b7ef924453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ee7592018b459192181937449b9218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71e71c214e144cdca4b710f653fc5767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1630d79a17e94066b15c8ede20e04df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ec72be01a9420f87904715b7da07df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e228e5376b842d2b884bda95b344913",
              "IPY_MODEL_06f09f03f43d4a55968a3385271ea456",
              "IPY_MODEL_dea106d8323a48739954069f9e0d286e"
            ],
            "layout": "IPY_MODEL_b1eb8a70babc48b4bbd682a497241a21"
          }
        },
        "5e228e5376b842d2b884bda95b344913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d65eb61769ac4352888e7bd83c1bd617",
            "placeholder": "​",
            "style": "IPY_MODEL_8e3539b502994fe8b3866bfa0612d805",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "06f09f03f43d4a55968a3385271ea456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322b3871c24c4c1cab939f0d2131ba35",
            "max": 905,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2df6fc6828204c2ab4994d57c33b2172",
            "value": 905
          }
        },
        "dea106d8323a48739954069f9e0d286e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ae0639bc2f449e92479891b3bb4cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_71e062b60e1f4175a7d831967e0a11b9",
            "value": " 905/905 [00:00&lt;00:00, 37.0kB/s]"
          }
        },
        "b1eb8a70babc48b4bbd682a497241a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65eb61769ac4352888e7bd83c1bd617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3539b502994fe8b3866bfa0612d805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "322b3871c24c4c1cab939f0d2131ba35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df6fc6828204c2ab4994d57c33b2172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8ae0639bc2f449e92479891b3bb4cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e062b60e1f4175a7d831967e0a11b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f619c3b3e6c04a988e02ce9522f1c9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a30704611bcd4106966c752a965279f9",
              "IPY_MODEL_a06e0d92011c41c7bce17ac0032ca83e",
              "IPY_MODEL_f1e8e841c02e422f8a01617133dd3653"
            ],
            "layout": "IPY_MODEL_69c3f695701941c48776f6cf37c16b5d"
          }
        },
        "a30704611bcd4106966c752a965279f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe82dedaacd944e68fe01a075152185c",
            "placeholder": "​",
            "style": "IPY_MODEL_62adcbc95f9340c6b09ec99aa7e1d1e0",
            "value": "Downloading config.json: 100%"
          }
        },
        "a06e0d92011c41c7bce17ac0032ca83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b204eefe3ad4acd93f0339ce8b9bcd1",
            "max": 4409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1929f591bdc1459c8196ff3484503dff",
            "value": 4409
          }
        },
        "f1e8e841c02e422f8a01617133dd3653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e94a81d49a94831ab382ef3684dac42",
            "placeholder": "​",
            "style": "IPY_MODEL_eab4c05f29224d7ca9427a3ea52ee301",
            "value": " 4.31k/4.31k [00:00&lt;00:00, 150kB/s]"
          }
        },
        "69c3f695701941c48776f6cf37c16b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe82dedaacd944e68fe01a075152185c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62adcbc95f9340c6b09ec99aa7e1d1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b204eefe3ad4acd93f0339ce8b9bcd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1929f591bdc1459c8196ff3484503dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e94a81d49a94831ab382ef3684dac42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab4c05f29224d7ca9427a3ea52ee301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f506e0f5b35349dd9669d2f392461e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a109948ec7304fc58415bf59bffc41f2",
              "IPY_MODEL_b6692798177145f4b940933e3edfae75",
              "IPY_MODEL_83ecc0e87811439e9d57d6cf508778df"
            ],
            "layout": "IPY_MODEL_d8fb5c3f0e2a4ba6928cce0af5f40de4"
          }
        },
        "a109948ec7304fc58415bf59bffc41f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7345d072b8b449a4b61924fe17847010",
            "placeholder": "​",
            "style": "IPY_MODEL_5647da50934b4227a915f5970a3eb09a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "b6692798177145f4b940933e3edfae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a8e8998a3c476f9ac606a6e2575cd7",
            "max": 1710671599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e36c829a1ced46fcba6932aca56b864c",
            "value": 1710671599
          }
        },
        "83ecc0e87811439e9d57d6cf508778df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b9d89fe2514a1fb47ee63c4551f878",
            "placeholder": "​",
            "style": "IPY_MODEL_59b8521a8d7947cd8b358a95b4266a4b",
            "value": " 1.59G/1.59G [00:26&lt;00:00, 66.0MB/s]"
          }
        },
        "d8fb5c3f0e2a4ba6928cce0af5f40de4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7345d072b8b449a4b61924fe17847010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5647da50934b4227a915f5970a3eb09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a8e8998a3c476f9ac606a6e2575cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36c829a1ced46fcba6932aca56b864c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92b9d89fe2514a1fb47ee63c4551f878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b8521a8d7947cd8b358a95b4266a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf3c48ad2b146fcb9a912d3aa976694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9d0dec94b2342af81c3ccdad856df3a",
              "IPY_MODEL_55f783d8783d4a1fb51f645b800f76b3",
              "IPY_MODEL_7850c5815a6c4600b9b58edc7de4a173"
            ],
            "layout": "IPY_MODEL_bceedab559654baf99a0d78b57e33753"
          }
        },
        "a9d0dec94b2342af81c3ccdad856df3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15ee1d576c54a9c8cfbb48b06f27b36",
            "placeholder": "​",
            "style": "IPY_MODEL_6c153cd22b3f42e3892e7cabdb534a86",
            "value": "Downloading preprocessor_config.json: 100%"
          }
        },
        "55f783d8783d4a1fb51f645b800f76b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0812b4aace38439ca511943e98f0e824",
            "max": 342,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7c5a1c7593c4d32ac50a70020b3526a",
            "value": 342
          }
        },
        "7850c5815a6c4600b9b58edc7de4a173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2f06738d424fcb963e42b23cceb2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_31ade7a1b503438cb01a70332e640b1e",
            "value": " 342/342 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "bceedab559654baf99a0d78b57e33753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15ee1d576c54a9c8cfbb48b06f27b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c153cd22b3f42e3892e7cabdb534a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0812b4aace38439ca511943e98f0e824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c5a1c7593c4d32ac50a70020b3526a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f2f06738d424fcb963e42b23cceb2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ade7a1b503438cb01a70332e640b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2504e2eebc944ec3a8bbc9bc8a26ca6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5e1f5821da8439aa94e6bbe768b6ee2",
              "IPY_MODEL_d626e31f13b443518d5fbaeeb1475b42",
              "IPY_MODEL_e8c5c6595afb4416addd7e9e5cc3c899"
            ],
            "layout": "IPY_MODEL_636c4b7c85144ccf87cde22dee54afc5"
          }
        },
        "a5e1f5821da8439aa94e6bbe768b6ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc8929a8b9c49299020595166430246",
            "placeholder": "​",
            "style": "IPY_MODEL_b273c9cf6118474ba45c4fdb34ef714d",
            "value": "Downloading config.json: 100%"
          }
        },
        "d626e31f13b443518d5fbaeeb1475b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743a7ebb065c49b989c384b9c3a03542",
            "max": 4549,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c47139ff03b94ab4a785347c3953edca",
            "value": 4549
          }
        },
        "e8c5c6595afb4416addd7e9e5cc3c899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac303bda3c534deab83738310aae0c5a",
            "placeholder": "​",
            "style": "IPY_MODEL_1e8b8fa5bcdf49df99fd342f29b7254a",
            "value": " 4.44k/4.44k [00:00&lt;00:00, 171kB/s]"
          }
        },
        "636c4b7c85144ccf87cde22dee54afc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc8929a8b9c49299020595166430246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b273c9cf6118474ba45c4fdb34ef714d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "743a7ebb065c49b989c384b9c3a03542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47139ff03b94ab4a785347c3953edca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac303bda3c534deab83738310aae0c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8b8fa5bcdf49df99fd342f29b7254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e1857b6f924bf39c3e06581c97a6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5726a70aaafd4a009308224b32b78905",
              "IPY_MODEL_bbf2d12b5f5247a1941debbaa019f1d4",
              "IPY_MODEL_83a96d7923a84f31b8df24d46019ae40"
            ],
            "layout": "IPY_MODEL_0b7a3c0a241d4c10bc327221832d13f5"
          }
        },
        "5726a70aaafd4a009308224b32b78905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838bda2e09984ac3bad418167dacc504",
            "placeholder": "​",
            "style": "IPY_MODEL_e639f442e21e45d9adf554a1064fe8d1",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "bbf2d12b5f5247a1941debbaa019f1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158cd6311d1d440997624992ccb7ef5c",
            "max": 1216067303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2599c318715457081d6050750f1878f",
            "value": 1216067303
          }
        },
        "83a96d7923a84f31b8df24d46019ae40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aea8fb1bb1f4ca0a4a1596642220b4d",
            "placeholder": "​",
            "style": "IPY_MODEL_75530fe9ed514fcc9a58889341abca7d",
            "value": " 1.13G/1.13G [00:18&lt;00:00, 68.4MB/s]"
          }
        },
        "0b7a3c0a241d4c10bc327221832d13f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838bda2e09984ac3bad418167dacc504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e639f442e21e45d9adf554a1064fe8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "158cd6311d1d440997624992ccb7ef5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2599c318715457081d6050750f1878f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aea8fb1bb1f4ca0a4a1596642220b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75530fe9ed514fcc9a58889341abca7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}